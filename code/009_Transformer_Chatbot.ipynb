{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "009_Transformer_Chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ_zqJ6mVq62"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnDiechvXjgi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fPnmNrrWZsD"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgAfvM-skvy8"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Layer, Lambda, Embedding, Dropout, LayerNormalization\n",
        "from keras import Input, Model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtoQgtTeWsxR"
      },
      "source": [
        "## 1. TPU Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWlPPW9cWxdh"
      },
      "source": [
        "### 1) TPU 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6204oSWgWcB_"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
        "    tpu = 'grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdHsN2sJWzk9"
      },
      "source": [
        "### 2) TPU Strategy 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qir7ls-W3ax"
      },
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR8rY6KSXwj-"
      },
      "source": [
        "## 2. Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAt6L86CXBXw"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\"\n",
        "\n",
        "train_data = pd.read_csv(url)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rrwU4CjPX6pC",
        "outputId": "7e6abd46-a942-4277-f814-1d859384e484"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckJiLTzqYAwi",
        "outputId": "607b9791-1978-43ba-ef83-d61be414dd5d"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11823"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpngkSqVYCvt",
        "outputId": "ea7028a1-5863-417b-dcb0-571e329966a9"
      },
      "source": [
        "train_data.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Q        0\n",
              "A        0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3fLDXceYNzv"
      },
      "source": [
        "## 3. Data Cleansing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXLzrNNVZi0q"
      },
      "source": [
        "### 1) 구두점 앞에 공백 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX-aoaS6YQTd"
      },
      "source": [
        "questions = []\n",
        "\n",
        "for sentence in train_data['Q'] :\n",
        "  sentence = re.sub(r\"([?.!,])\" , r\" \\1 \" , sentence)\n",
        "  sentence = sentence.strip()\n",
        "  questions.append(sentence)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grE_qRrOZQat"
      },
      "source": [
        "answers = []\n",
        "\n",
        "for sentence in train_data['A'] :\n",
        "  sentence = re.sub(r\"([?.!,])\" , r\" \\1 \" , sentence)\n",
        "  sentence = sentence.strip()\n",
        "  answers.append(sentence)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZPpVNI7ZbOr",
        "outputId": "5cd3d1de-489f-452a-c3e9-750aaf0b3bd7"
      },
      "source": [
        "print(questions[:5])\n",
        "print(answers[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
            "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-Sz8EUYZn6o"
      },
      "source": [
        "### 2) 단어집합 생성\n",
        "- 서브워드 텍스트 인코더 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRZHKmDTZeaH"
      },
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size = 2**13)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAIzcJRCaPkG"
      },
      "source": [
        "- 시작토큰, 종료토큰에 대한 정수 부여"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUv6LSddaC9m"
      },
      "source": [
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작토큰과 종료토큰을 고려하여 단어집합의 크기를 +2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAkF1wTWae4c",
        "outputId": "4de7fe07-8261-454c-827f-01cc0a8a7c4f"
      },
      "source": [
        "print('시작 토큰 번호: ' , START_TOKEN)\n",
        "print('종료 토큰 번호: ' , END_TOKEN)\n",
        "print('단어 집합의 크기: ' , VOCAB_SIZE)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "시작 토큰 번호:  [8178]\n",
            "종료 토큰 번호:  [8179]\n",
            "단어 집합의 크기:  8180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0cPIldNauE4"
      },
      "source": [
        "### 3) 정수 인코딩과 패딩\n",
        "- .encode() 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtEfDUnPawQ3",
        "outputId": "55c960a3-5b56-402f-c10c-8b25bbc576e5"
      },
      "source": [
        "# 임의의 입력 문장을 sample_string에 저장\n",
        "sample_string = questions[20]\n",
        "\n",
        "# encode(): 텍스트 시퀀스 -> 정수 시퀀스\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print('정수 인코딩 후의 문장: {}' .format(tokenized_string))\n",
        "\n",
        "# decode(): 정수 시퀀스 -> 텍스트 시퀀스\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print('기존 문장: {}' .format(original_string))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장: [5766, 611, 3509, 141, 685, 3747, 849]\n",
            "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLiasAbCj4IY"
      },
      "source": [
        "- tokenized_and_filter() 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnE_zPg_j-c2"
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def tokenize_and_filter(inputs, outputs) :\n",
        "  tokenized_inputs, tokenized_outputs = [] , []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs) :\n",
        "    # encode(토큰화 + 정수인코딩), 시작 토큰과 종료 토큰 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 패딩\n",
        "  tokenized_inputs = pad_sequences(tokenized_inputs,\n",
        "                                   maxlen = MAX_LENGTH,\n",
        "                                   padding = 'post')\n",
        "  tokenized_outputs = pad_sequences(tokenized_outputs,\n",
        "                                    maxlen = MAX_LENGTH,\n",
        "                                    padding = 'post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOgGp7y-kC1q"
      },
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQmJVuYnlPjk",
        "outputId": "7d5928c9-e82a-4f08-b64d-b16a04f6533b"
      },
      "source": [
        "questions.shape, answers.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11823, 40), (11823, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvVbgSV6l6zW"
      },
      "source": [
        "## 4. 인코더와 디코더 입력, 레이블 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTTY_93Ql_iw"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서 시작토큰 제거\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {'inputs' : questions,\n",
        "     'dec_inputs' : answers[:, :-1]},   # 디코더의 입력(마지막 패딩 토큰 제거)\n",
        "    {'outputs' : answers[:, 1:]}        # 맨 처음 토큰(시작토큰) 제거\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2a69Grfm92S",
        "outputId": "5c82c498-c325-4d88-ccc5-13e35944e94b"
      },
      "source": [
        "print(answers[0])           # 기존 샘플\n",
        "print(answers[:1][:, :-1])  # 마지막 패딩 토큰 제거하면서 길이가 39가 됨\n",
        "print(answers[:1][:, 1:])   # 시작토큰이 제거되면서 길이가 39가 됨"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfMkBrTPoqR4"
      },
      "source": [
        "## 5. 트랜스포머 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciaDr5BXpEK7"
      },
      "source": [
        "class PositionalEncoding(Layer) :\n",
        "  def __init__(self, position, d_model) :\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i//2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position = tf.range(position, dtype = tf.float32)[:, tf.newaxis],\n",
        "        i = tf.range(d_model, dtype = tf.float32)[tf.newaxis, :],\n",
        "        d_model = d_model\n",
        "    )\n",
        "\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis = -1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    print(pos_encoding.shape)\n",
        "\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EJACNWOpN7P"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask) :\n",
        "\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b = True)\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(logits, axis = -1)\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnApyp-tpXsk"
      },
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name = 'multi_head_attention'):\n",
        "    super(MultiHeadAttention, self).__init__(name = name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "    self.query_dense = Dense(units = d_model) # units: 뉴런 수\n",
        "    self.key_dense = Dense(units = d_model)\n",
        "    self.value_dense = Dense(units = d_model)\n",
        "    self.dense = Dense(units = d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape = (batch_size, -1, self.num_heads, self.depth)) # (1, 1, 4, 32)\n",
        "    \n",
        "    return tf.transpose(inputs, perm = [0, 2, 1, 3]) # (1, 4, 1, 32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], \\\n",
        "    inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    query = self.query_dense(query) \n",
        "    key = self.key_dense(key)       \n",
        "    value = self.value_dense(value)\n",
        "  \n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3])\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "   \n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vv8qKl-pri5"
      },
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name = 'encoder_layer'):\n",
        "  inputs = Input(shape = (None, d_model), name = 'inputs')\n",
        "  padding_mask = Input(shape = (1, 1, None), name = 'padding_mask')\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name = 'attention')({\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  \n",
        "  attention = Dropout(rate = dropout)(attention)\n",
        "  attention = LayerNormalization(epsilon = 1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = Dense(units = dff, activation = 'relu')(attention)\n",
        "  outputs = Dense(units = d_model)(outputs)\n",
        "\n",
        "  outputs = Dropout(rate = dropout)(outputs)\n",
        "  outputs = LayerNormalization(epsilon = 1e-6)(attention + outputs)\n",
        "\n",
        "  return Model(inputs = [inputs, padding_mask],\n",
        "               outputs = outputs, name = name)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_i1Nkcypy42"
      },
      "source": [
        "def encoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, name = 'encoder'):\n",
        "  inputs = Input(shape = (None,) , name = 'inputs')\n",
        "  padding_mask = Input(shape = (1, 1, None), name = 'padding_mask')\n",
        "\n",
        "  embeddings = Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = Dropout(rate = dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        dff = dff,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = 'encoder_layer_{}' .format(i))([outputs, padding_mask])\n",
        "\n",
        "  return Model(inputs = [inputs, padding_mask],\n",
        "               outputs = outputs, name = name)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It2w4XdOp356"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  \n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doi9_hq3p7Ws"
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
        "\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqEvxZK-p_OP"
      },
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout,\n",
        "                  name = 'decoder_layer'):\n",
        "  inputs = Input(shape = (None, d_model), name = 'inputs')\n",
        "  enc_outputs = Input(shape = (None, d_model), name = 'encoder_outputs')\n",
        "\n",
        "  look_ahead_mask = Input(shape = (1, None, None), name = 'look_ahead_mask')\n",
        "  padding_mask = Input(shape = (1, 1, None), name = 'padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name = 'attention_1')(inputs = {\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : look_ahead_mask\n",
        "      })\n",
        "\n",
        "  attention1 = LayerNormalization(epsilon = 1e-6)(attention1 + inputs)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name = 'attention_2')(inputs = {\n",
        "          'query' : attention1, \n",
        "          'key' : enc_outputs, \n",
        "          'value' : enc_outputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  \n",
        "  attention2 = Dropout(rate = dropout)(attention2)\n",
        "  attention2 = LayerNormalization(epsilon = 1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = Dense(units = dff, activation = 'relu')(attention2)\n",
        "  outputs = Dense(units = d_model)(outputs)\n",
        "\n",
        "  outputs = Dropout(rate = dropout)(outputs)\n",
        "  outputs = LayerNormalization(epsilon = 1e-6)(outputs + attention2)\n",
        "\n",
        "  return Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT9PtQINqIHC"
      },
      "source": [
        "def decoder(vocab_size, num_layers, dff, d_model, num_heads, dropout,\n",
        "            name = 'docoder'):\n",
        "  inputs = Input(shape = (None,), name = 'inputs')\n",
        "  enc_outputs = Input(shape = (None, d_model), name = 'encoder_outputs')\n",
        "\n",
        "  look_ahead_mask = Input(shape = (1, None, None), name = 'look_ahead_mask')\n",
        "  padding_mask = Input(shape = (1, 1, None), name = 'padding_mask')\n",
        "\n",
        "  embeddings = Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = Dropout(rate = dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        dff = dff, d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = 'decoder_layer_{}' .format(i))(\n",
        "            inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "        \n",
        "  return Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrlQupmPqNuC"
      },
      "source": [
        "def transformer(vocab_size, num_layers, dff, d_model, num_heads, dropout,\n",
        "                name = 'transformer'):\n",
        "  \n",
        "  inputs = Input(shape = (None,), name = 'inputs')\n",
        "  dec_inputs = Input(shape = (None,), name = 'dec_inputs')\n",
        "\n",
        "  enc_padding_mask = Lambda(\n",
        "      create_padding_mask,\n",
        "      output_shape = (1, 1, None),\n",
        "      name = 'enc_padding_mask')(inputs)\n",
        "  \n",
        "  look_ahead_mask = Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape = (1, 1, None),\n",
        "      name = 'look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  dec_padding_mask = Lambda(\n",
        "      create_padding_mask,\n",
        "      output_shape = (1, 1, None),\n",
        "      name = 'dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size = vocab_size,\n",
        "      num_layers = num_layers,\n",
        "      dff = dff,\n",
        "      d_model = d_model,\n",
        "      num_heads = num_heads,\n",
        "      dropout = dropout)(inputs = [inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size = vocab_size,\n",
        "      num_layers = num_layers,\n",
        "      dff = dff,\n",
        "      d_model = d_model,\n",
        "      num_heads = num_heads,\n",
        "      dropout = dropout)(inputs = [dec_inputs, enc_outputs,\n",
        "                                   look_ahead_mask,\n",
        "                                   dec_padding_mask])\n",
        "\n",
        "  outputs = Dense(units = vocab_size, name = 'outputs')(dec_outputs)\n",
        "\n",
        "  return Model(inputs = [inputs, dec_inputs],\n",
        "               outputs = outputs, name = name)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFrmGZqCqVFJ"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T1JlXTVrN6n"
      },
      "source": [
        "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmx_fW5qr28W"
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape = (-1, MAX_LENGTH -1))\n",
        "\n",
        "  return keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUQ7YzzRXPWQ"
      },
      "source": [
        "## 6. 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv_4Yz-mV10q",
        "outputId": "9b170a61-52af-49f6-d183-23ee903f4823"
      },
      "source": [
        "%%time\n",
        "\n",
        "D_MODEL = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "def create_model():\n",
        "  model = transformer(\n",
        "      vocab_size = VOCAB_SIZE,\n",
        "      num_layers = NUM_LAYERS,\n",
        "      dff = DFF,\n",
        "      d_model = D_MODEL,\n",
        "      num_heads = NUM_HEADS,\n",
        "      dropout = DROPOUT)\n",
        "  return model"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 12.4 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04_DpHtbq9eH",
        "outputId": "b94ce8ff-8464-4450-9847-1388b6df59fc"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  learning_rate = CustomSchedule(D_MODEL)\n",
        "  optimizer = keras.optimizers.Adam(\n",
        "      learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)  \n",
        "\n",
        "  model.compile(optimizer = optimizer,\n",
        "                  loss = loss_function,\n",
        "                  metrics = [accuracy])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 8180, 256)\n",
            "(1, 8180, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2O0fWLXtADZ",
        "outputId": "d20248ab-bd52-4755-99f9-bd8e3c10a23f"
      },
      "source": [
        "%%time\n",
        "EPOCHS = 10\n",
        "hist = model.fit(dataset, epochs = EPOCHS)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "185/185 [==============================] - 6s 31ms/step - loss: 0.0036 - accuracy: 0.1742\n",
            "Epoch 2/10\n",
            "185/185 [==============================] - 6s 32ms/step - loss: 0.0034 - accuracy: 0.1742\n",
            "Epoch 3/10\n",
            "185/185 [==============================] - 6s 32ms/step - loss: 0.0033 - accuracy: 0.1742\n",
            "Epoch 4/10\n",
            "185/185 [==============================] - 6s 32ms/step - loss: 0.0031 - accuracy: 0.1742\n",
            "Epoch 5/10\n",
            "185/185 [==============================] - 6s 31ms/step - loss: 0.0032 - accuracy: 0.1742\n",
            "Epoch 6/10\n",
            "185/185 [==============================] - 6s 30ms/step - loss: 0.0029 - accuracy: 0.1743\n",
            "Epoch 7/10\n",
            "185/185 [==============================] - 6s 31ms/step - loss: 0.0029 - accuracy: 0.1743\n",
            "Epoch 8/10\n",
            "185/185 [==============================] - 6s 31ms/step - loss: 0.0029 - accuracy: 0.1744\n",
            "Epoch 9/10\n",
            "185/185 [==============================] - 6s 32ms/step - loss: 0.0026 - accuracy: 0.1744\n",
            "Epoch 10/10\n",
            "185/185 [==============================] - 6s 31ms/step - loss: 0.0028 - accuracy: 0.1743\n",
            "CPU times: user 20.7 s, sys: 2.92 s, total: 23.7 s\n",
            "Wall time: 1min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFFJLvF5u3CW"
      },
      "source": [
        "## 7. 챗봇 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY1JU5JWq0CX"
      },
      "source": [
        "def evaluate(sentence) :\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis = 0)\n",
        "  \n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 예측 시작\n",
        "  for i in range(MAX_LENGTH) :\n",
        "    predictions = model(inputs = [sentence, output],\n",
        "                        training = False)\n",
        "    \n",
        "    # 현재(마지막) 시점의 예측 단어를 받아옴\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis = -1), tf.int32)\n",
        "\n",
        "    # 마지막 시점의 예측 단어가 종료 토큰이면 예측 중단\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "       break\n",
        "\n",
        "    # 마지막 시점의 예측 단어를 출력에 연결\n",
        "    output = tf.concat([output, predicted_id], axis = -1)\n",
        "\n",
        "  return tf.squeeze(output, axis = 0)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsabzTUev2fW"
      },
      "source": [
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "  \n",
        "  print('Input: {}' .format(sentence))\n",
        "  print('Output: {}' .format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uisfpNc0wFFP"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = re.sub(r'([?.!,])' , r' \\1' , sentence)\n",
        "  sentence = sentence.strip()\n",
        "\n",
        "  return sentence"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "vY2D7ASucBXC",
        "outputId": "9fbc0d43-0e93-417f-93d1-373989e3a392"
      },
      "source": [
        "predict('안녕')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 안녕\n",
            "Output: 안녕하세요 .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'안녕하세요 .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "B_YgdrbScCyM",
        "outputId": "bae6099b-24d9-44cc-c01d-0019d2af6f7b"
      },
      "source": [
        "predict('뭐해')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 뭐해\n",
            "Output: 냉장고 파먹기 해보세요 .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'냉장고 파먹기 해보세요 .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "SqBUYAD3cIYe",
        "outputId": "8186b072-acc5-49bc-9f71-b58a7ae10d00"
      },
      "source": [
        "predict('냉장고를 왜 파먹어 ㅋㅋ')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 냉장고를 왜 파먹어 ㅋㅋ\n",
            "Output: 슈퍼라도 가서 쇼핑하고 오세요 .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'슈퍼라도 가서 쇼핑하고 오세요 .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "z16i-PGNcNbS",
        "outputId": "e3aad060-79ae-41fa-9987-e185d591fc4e"
      },
      "source": [
        "predict('뭐 살까?')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 뭐 살까?\n",
            "Output: 함께 충분한 대화를 하고 상담을 받아보는 게 좋겠어요 .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'함께 충분한 대화를 하고 상담을 받아보는 게 좋겠어요 .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "RbUQPmUWcRCP",
        "outputId": "6996cdd9-204e-495b-ea76-eb5b74b7c1d2"
      },
      "source": [
        "predict('호엥')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 호엥\n",
            "Output: 음~ 곰곰히 생각해보세요 .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'음~ 곰곰히 생각해보세요 .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "7wZeB6OacUx4",
        "outputId": "3364e5f7-61db-436e-ce76-805695ee3c7d"
      },
      "source": [
        "predict('졸려')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 졸려\n",
            "Output: 오늘 일찍 주무세요 .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'오늘 일찍 주무세요 .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAeYsAtSdgVu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}